{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 28 members:\n",
    "- Jingze Tian (CCID)\n",
    "- Letian Ren (CCID)\n",
    "- Essam Gouda (egouda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Regression\n",
    "- Linear Regression for no_of_Mosquito = function(weather_features)\n",
    "- Linear Regression for no_of_Mosquito_female = function(weather_features)\n",
    "- Linear Regression for no_of_Mosquito_male = function(weather_features)\n",
    "- Polynomial Regression for no_of_Mosquito_female = function(weather_features)\n",
    "- Polynomial Regression for no_of_Mosquito_male = function(weather_features)\n",
    "\n",
    "#### Variations for each model:\n",
    "- Different cost functions were tested\n",
    "- Model without normalization and standardization, model with normalization only, model with standardization only, model with both normalization and standardization.\n",
    "- Feature selection\n",
    "- model statistics compared at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white bg for sns plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv files (datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('./data/weather_data.csv')\n",
    "mos_data = pd.read_csv('./data/mosquito_data_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize mosquito trap date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_list = []\n",
    "for i in mos_data['Trap Date']:\n",
    "    i = str(i)\n",
    "    t1 = time.strptime(i,\"%m/%d/%Y %H:%M:%S AM\")\n",
    "    t2 = time.strftime(\"%Y-%m-%d\", t1)\n",
    "    t_list.append(t2)\n",
    "\n",
    "mos_data['Trap Date'] = t_list\n",
    "\n",
    "mos_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align date ranges in both datasets\n",
    "Both datasets have different date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mos_data['Trap Date'] = pd.to_datetime(mos_data['Trap Date'])\n",
    "start_remove = min(weather_data['date_time_local'])\n",
    "end_remove = max(weather_data['date_time_local'])\n",
    "mos_data_1 = mos_data.loc[(mos_data[\"Trap Date\"] > start_remove) & (mos_data[\"Trap Date\"] < end_remove) ]\n",
    "mos_date_start = str(mos_data_1['Trap Date'].dt.date.min())\n",
    "mos_date_end = str(mos_data_1['Trap Date'].dt.date.max())\n",
    "mos_date_range = mos_date_start +' to ' + mos_date_end\n",
    "print(\"Range of dates in mosquito dataset is {}\".format(mos_date_range))\n",
    "\n",
    "\n",
    "mos_range = (mos_data['Trap Date'] > mos_date_start) & (mos_data['Trap Date'] < mos_date_end)\n",
    "mos_data = mos_data.loc[mos_range]\n",
    "print(mos_data) #\n",
    "mos_data = mos_data.sort_values(by='Trap Date')\n",
    "mos_data #final mos_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get total count for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mos_count = mos_data.groupby([\"Trap Date\"]).agg({\n",
    "    \"Count\":\"sum\",\n",
    "})\n",
    "mos_count[mos_count['Count'] == mos_count['Count'].max()]\n",
    "\n",
    "mos_count.head() ####number of mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mos_count.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that IDd and Include columns contains many NaN values so they will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mos_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.drop(columns=['IDd', 'Include'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select date for weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date1 = '2017-05-10'#one week before 2017-05-16\n",
    "end_date1 = '2017-09-26'\n",
    "start_date2 = '2018-05-09'#one week before 2017-05-15\n",
    "end_date2 = '2018-09-18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop MST columns\n",
    "Drop columns with too many NaNs\n",
    "Drop unixtime columns as they are redundent\n",
    "Drop wind_dir column as wind_dir_10s gives us the angle of the wind so its redundent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############Drop MST and columns with too many NaNs and unixtime##################\n",
    "weather_data.drop(columns=[\"visibility\", \"cloud_cover_4\", \"cloud_cover_8\", \"cloud_cover_10\", \"solar_radiation\", \"wind_gust\", \"windchill\", \"humidex\", 'unixtime', 'wind_dir'], inplace=True)\n",
    "weather_data = weather_data.loc[weather_data['date_time_local'].str.contains('MDT')]\n",
    "\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_list = []\n",
    "for i in weather_data['date_time_local']:\n",
    "    i = str(i)\n",
    "    t1 = time.strptime(i,\"%Y-%m-%d %H:%M:%S MDT\")\n",
    "    t2 = time.strftime(\"%Y-%m-%d\", t1)\n",
    "    t_list.append(t2)\n",
    "\n",
    "weather_data['date_time_local'] = t_list\n",
    "#print(weather_data)\n",
    "\n",
    "weather_data['date_time_local'] = pd.to_datetime(weather_data['date_time_local'])\n",
    "weather_range1 = (weather_data['date_time_local'] >= start_date1) & (weather_data['date_time_local'] <= end_date1)\n",
    "weather_data1 = weather_data.loc[weather_range1]\n",
    "weather_data1 = weather_data1.sort_values(by='date_time_local')\n",
    "#print(weather_data1) \n",
    "\n",
    "weather_range2 = (weather_data['date_time_local'] >= start_date2) & (weather_data['date_time_local'] <= end_date2)\n",
    "weather_data2 = weather_data.loc[weather_range2]\n",
    "weather_data2 = weather_data2.sort_values(by='date_time_local')\n",
    "#print(weather_data2) \n",
    "weather_data = weather_data1.append(weather_data2)\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN for weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(weather_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fill the NaNs we will group the weather data by day and there is 3 ways to do that for each column:\n",
    "- By mean\n",
    "- By mode\n",
    "- By median\n",
    "\n",
    "for each day, to do so we will need to visualize the distribution for each column and ensure that it stays similar after grouping to not add any bias to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pressure station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data['pressure_station'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pressure_station_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'pressure_station': lambda x: round(x.mean(), 2)  \n",
    "})\n",
    "\n",
    "pressure_station_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'pressure_station'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = pressure_station_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "pressure_station_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['pressure_station'], pressure_station_mean['pressure_station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pressure_station_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'pressure_station': lambda x: x.value_counts().index[0]  \n",
    "})\n",
    "\n",
    "pressure_station_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key_to_test = 'pressure_station'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = pressure_station_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "pressure_station_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['pressure_station'], pressure_station_mode['pressure_station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_station_median = weather_data.groupby('date_time_local').agg({\n",
    "  'pressure_station': lambda x: x.median() \n",
    "})\n",
    "\n",
    "pressure_station_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key_to_test = 'pressure_station'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = pressure_station_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "pressure_station_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['pressure_station'], pressure_station_median['pressure_station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that for pressure station mode has the highest p-value so it will be chosen for grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pressure sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data['pressure_sea'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_sea_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'pressure_sea': lambda x: round(x.mean(), 2)  \n",
    "})\n",
    "\n",
    "pressure_sea_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'pressure_sea'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = pressure_sea_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "pressure_sea_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['pressure_sea'], pressure_sea_mean['pressure_sea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_sea_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'pressure_sea': lambda x: x.value_counts().index[0]  \n",
    "})\n",
    "\n",
    "pressure_sea_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'pressure_sea'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = pressure_sea_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "pressure_sea_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['pressure_sea'], pressure_sea_mode['pressure_sea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_sea_median = weather_data.groupby('date_time_local').agg({\n",
    "  'pressure_sea': lambda x: x.median() \n",
    "})\n",
    "\n",
    "pressure_sea_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'pressure_sea'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = pressure_sea_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "pressure_sea_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['pressure_sea'], pressure_sea_median['pressure_sea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that for pressure sea median has the highest p-value so it will be chosen for grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind_dir_10s\n",
    "This column represents the wind direction in angles so taking a mean or median doesn't make much sense and mode is expected to be the best method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['wind_dir_10s'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_10s_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'wind_dir_10s': lambda x: round(x.mean(), 1)  \n",
    "})\n",
    "\n",
    "wind_dir_10s_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'wind_dir_10s'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = wind_dir_10s_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "wind_dir_10s_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['wind_dir_10s'], wind_dir_10s_mean['wind_dir_10s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_10s_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'wind_dir_10s': lambda x: x.value_counts().index[0]   \n",
    "})\n",
    "\n",
    "wind_dir_10s_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'wind_dir_10s'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = wind_dir_10s_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "wind_dir_10s_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['wind_dir_10s'], wind_dir_10s_mode['wind_dir_10s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_10s_median = weather_data.groupby('date_time_local').agg({\n",
    "  'wind_dir_10s': lambda x: x.median()  \n",
    "})\n",
    "\n",
    "wind_dir_10s_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'wind_dir_10s'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = wind_dir_10s_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "wind_dir_10s_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['wind_dir_10s'], wind_dir_10s_median['wind_dir_10s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected mode will be the chosen value for wind_dir_10s column as it has the highest p-value, it can be seen that mean doesn't even follow the same distribution and the median barely does follow it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['wind_speed'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'wind_speed': lambda x: round(x.mean(),1)  \n",
    "})\n",
    "\n",
    "wind_speed_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'wind_speed'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = wind_speed_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "wind_speed_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['wind_speed'], wind_speed_mean['wind_speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'wind_speed': lambda x: x.value_counts().index[0]  \n",
    "})\n",
    "\n",
    "wind_speed_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'wind_speed'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = wind_speed_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "wind_speed_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['wind_speed'], wind_speed_mode['wind_speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_median = weather_data.groupby('date_time_local').agg({\n",
    "  'wind_speed': lambda x: x.median()  \n",
    "})\n",
    "\n",
    "wind_speed_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'wind_speed'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = wind_speed_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "wind_speed_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['wind_speed'], wind_speed_median['wind_speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode will be used for wind_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative_humidty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['relative_humidity'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_humidity_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'relative_humidity': lambda x: round(x.mean(),1)\n",
    "})\n",
    "\n",
    "relative_humidity_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'relative_humidity'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = relative_humidity_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "relative_humidity_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['relative_humidity'], relative_humidity_mean['relative_humidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_humidity_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'relative_humidity': lambda x: x.value_counts().index[0]\n",
    "})\n",
    "\n",
    "relative_humidity_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'relative_humidity'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = relative_humidity_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "relative_humidity_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['relative_humidity'], relative_humidity_mode['relative_humidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_humidity_median = weather_data.groupby('date_time_local').agg({\n",
    "  'relative_humidity': lambda x: x.median()\n",
    "})\n",
    "\n",
    "relative_humidity_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'relative_humidity'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = relative_humidity_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "relative_humidity_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['relative_humidity'], relative_humidity_median['relative_humidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping relative_humidty will introduce bias in the dataset so it will be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dew_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['dew_point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dew_point_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'dew_point': lambda x: round(x.mean(),1)\n",
    "})\n",
    "\n",
    "dew_point_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'dew_point'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = dew_point_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "dew_point_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['dew_point'], dew_point_mean['dew_point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dew_point_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'dew_point': lambda x: x.value_counts().index[0]\n",
    "})\n",
    "\n",
    "dew_point_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'dew_point'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = dew_point_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "dew_point_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['dew_point'], dew_point_mode['dew_point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dew_point_median = weather_data.groupby('date_time_local').agg({\n",
    "  'dew_point': lambda x: x.median()\n",
    "})\n",
    "\n",
    "dew_point_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'dew_point'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = dew_point_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "dew_point_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['dew_point'], dew_point_median['dew_point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode will be used for dew_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['temperature'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'temperature': lambda x: round(x.mean(),1)\n",
    "})\n",
    "\n",
    "temperature_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'temperature'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = temperature_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "temperature_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['temperature'], temperature_mean['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'temperature': lambda x: x.value_counts().index[0]\n",
    "})\n",
    "\n",
    "temperature_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'temperature'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = temperature_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "temperature_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['temperature'], temperature_mode['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_median = weather_data.groupby('date_time_local').agg({\n",
    "  'temperature': lambda x: x.median()\n",
    "})\n",
    "\n",
    "temperature_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'temperature'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = temperature_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "temperature_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['temperature'], temperature_median['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode will be used for temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['health_index'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_index_mean = weather_data.groupby('date_time_local').agg({\n",
    "  'health_index': lambda x: round(x.mean(),1)\n",
    "})\n",
    "\n",
    "health_index_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'health_index'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = health_index_mean[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "health_index_mean[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mean data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['health_index'], health_index_mean['health_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_index_mode = weather_data.groupby('date_time_local').agg({\n",
    "  'health_index': lambda x: x.value_counts().index[0]\n",
    "})\n",
    "\n",
    "health_index_mode.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'health_index'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = health_index_mode[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "health_index_mode[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Mode data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['health_index'], health_index_mode['health_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_index_median = weather_data.groupby('date_time_local').agg({\n",
    "  'health_index': lambda x: x.median()\n",
    "})\n",
    "\n",
    "health_index_median.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_test = 'health_index'\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = weather_data[key_to_test].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "weather_data[key_to_test].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax = health_index_median[key_to_test].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.6)\n",
    "health_index_median[key_to_test].plot(kind='density', color='orange')\n",
    "\n",
    "\n",
    "ax.legend(['Original data', 'Median data'])\n",
    "ax.set(xlabel=key_to_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(weather_data['health_index'], health_index_median['health_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean will be used for health_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping weather data by date\n",
    "- Pressure station by mode\n",
    "- Pressure sea by median\n",
    "- wind_dir_10s by mode\n",
    "- wind_speed by mode\n",
    "- relative_humidty ignored\n",
    "- dew_point by mode\n",
    "- temperature by mode\n",
    "- health_index by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weather_data_grouped = weather_data.groupby('date_time_local', as_index=False).agg({\n",
    "    'pressure_station': lambda x: x.value_counts().index[0],\n",
    "    'pressure_sea': lambda x: x.median(),\n",
    "    'wind_dir_10s': lambda x: x.value_counts().index[0],\n",
    "    'wind_speed': lambda x: x.value_counts().index[0],\n",
    "    'dew_point': lambda x: x.value_counts().index[0],\n",
    "    'temperature': lambda x: x.value_counts().index[0],\n",
    "    'health_index': lambda x: round(x.mean(), 1)\n",
    "})\n",
    "\n",
    "print(len(weather_data_grouped.index))\n",
    "\n",
    "weather_data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_grouped.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further group weather data by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_grouped.sort_values('date_time_local', inplace=True)\n",
    "weather_data_grouped.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_grouped = weather_data_grouped.groupby(weather_data_grouped.index // 7).agg({\n",
    "    'date_time_local': 'last',\n",
    "    'pressure_station': lambda x: x.value_counts().index[0],\n",
    "    'pressure_sea': lambda x: x.median(),\n",
    "    'wind_dir_10s': lambda x: x.value_counts().index[0],\n",
    "    'wind_speed': lambda x: x.value_counts().index[0],\n",
    "    'dew_point': lambda x: x.value_counts().index[0],\n",
    "    'temperature': lambda x: x.value_counts().index[0],\n",
    "    'health_index': lambda x: round(x.mean(), 1)\n",
    "})\n",
    "\n",
    "print(len(weather_data_grouped.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping mosquito data\n",
    "\n",
    "\n",
    "There are 3 candidate columns to group mosquito data by:\n",
    "- Trap_date: date of trapping mosquitos\n",
    "- Genus: When biologists talk about a genus, they mean one or more species of animals or plants that are closely related to each other. Low-level taxonomic ranking for biological classification.\n",
    "- Specific Epithet: lowest taxonomic rank and having common characteristics and (usually) capable of mating with one another.\n",
    "\n",
    "Add Gender for part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mos_data_grouped = mos_data.groupby(['Trap Date'], as_index=False).agg({\n",
    "    'Count' : 'sum',\n",
    "    'Genus': lambda x: x.value_counts().index[0],\n",
    "    'Gender': lambda x: x.value_counts().index[0]\n",
    "})\n",
    "\n",
    "print(len(mos_data_grouped.index))\n",
    "\n",
    "mos_data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(left=mos_data_grouped, right=weather_data_grouped, left_on='Trap Date', right_on='date_time_local')\n",
    "\n",
    "print(len(merged_data.index))\n",
    "\n",
    "merged_data.drop(columns=['date_time_local'], inplace=True) #redundent\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features\n",
    "- isWarm: if temperature is above 20 = 1, else = 0.\n",
    "- add genusCat for Genus\n",
    "- add genderCat female = 1, male = 0\n",
    "- add delta_pressure = pressure_station - pressure_sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['isWarm'] = np.where(merged_data['temperature'] >= 20, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Genus'] = merged_data['Genus'].astype('category')\n",
    "merged_data['genusCat'] = merged_data['Genus'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data['genderCat'] = np.where(merged_data['Gender'] == \"Female\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[\"delta_pressure\"] = merged_data.apply(lambda x: x['pressure_station'] - x['pressure_sea'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Linear Regression for no_of_Mosquito = function(weather_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(merged_data['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_data['Count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_data = merged_data[merged_data['Count'] < merged_data['Count'].describe()['75%']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(merged_data.corr(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['wind_dir_10s', 'wind_speed', 'genusCat', 'delta_pressure']\n",
    "X = merged_data[x_cols]\n",
    "y = merged_data['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_cols = ['wind_dir_10s', 'wind_speed', 'delta_pressure']\n",
    "\n",
    "\n",
    "X_stand = X.copy()\n",
    "X_norm = X.copy()\n",
    "X_both = X.copy()\n",
    "\n",
    "X_stand[x_cols] = StandardScaler().fit_transform(X[x_cols])\n",
    "X_norm[x_cols] = X[x_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "X_both[x_cols] = StandardScaler().fit_transform(X[x_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))[x_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "X_train_stand, X_test_stand, y_train_stand, y_test_stand = train_test_split(X_stand, y, test_size=test_size, random_state=42)\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, test_size=test_size, random_state=42)\n",
    "X_train_both, X_test_both, y_train_both, y_test_both = train_test_split(X_both, y, test_size=test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "\n",
    "lin_reg_norm = LinearRegression()\n",
    "lin_reg_norm.fit(X_train_norm,y_train_norm)\n",
    "\n",
    "lin_reg_stand = LinearRegression()\n",
    "lin_reg_stand.fit(X_train_stand,y_train_stand)\n",
    "\n",
    "lin_reg_both = LinearRegression()\n",
    "lin_reg_both.fit(X_train_both,y_train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_reg.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lin_reg_norm.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg_norm.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lin_reg_stand.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg_stand.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lin_reg_both.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg_both.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = lin_reg.predict(X_test)\n",
    "pred_norm = lin_reg_norm.predict(X_test_norm)\n",
    "pred_stand = lin_reg_stand.predict(X_test_stand)\n",
    "pred_both = lin_reg_both.predict(X_test_both)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.scatter(y_test, pred, c='#2ca02c', marker='x', label='Original data')\n",
    "ax.scatter(y_test_norm, pred, c='r', marker='o', label='Normalized data')\n",
    "ax.scatter(y_test_stand, pred, c='b', marker='+', label='Standardized data')\n",
    "ax.scatter(y_test_both, pred, c='y', marker='s', label='Both data')\n",
    "\n",
    "plt.legend(loc='best');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot((y_test - pred), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lin_reg.predict(X_test)\n",
    "train_pred = lin_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred_norm = lin_reg_norm.predict(X_test_norm)\n",
    "train_pred_norm = lin_reg_norm.predict(X_train_norm)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_norm, test_pred_norm)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_norm, train_pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred_stand = lin_reg_stand.predict(X_test_stand)\n",
    "train_pred_stand = lin_reg_stand.predict(X_train_stand)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_stand, test_pred_stand)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_stand, train_pred_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred_both = lin_reg_both.predict(X_test_both)\n",
    "train_pred_both = lin_reg_both.predict(X_train_both)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_both, test_pred_both)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_both, train_pred_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())], [\"Linear Regression w/ norm\", *evaluate(y_test_norm, test_pred_norm) , cross_val(LinearRegression())], [\"Linear Regression w/ stand\", *evaluate(y_test_stand, test_pred_stand) , cross_val(LinearRegression())],[\"Linear Regression w/ both\", *evaluate(y_test_both, test_pred_both) , cross_val(LinearRegression())]], \n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: count depending on Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mos_data_grouped_B = mos_data.groupby(['Trap Date', 'Gender'], as_index=False).agg({\n",
    "    'Count' : 'sum',\n",
    "    'Genus': lambda x: x.value_counts().index[0],\n",
    "})\n",
    "\n",
    "print(len(mos_data_grouped_B.index))\n",
    "\n",
    "mos_data_grouped_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data_grouped_B_females = mos_data_grouped_B[mos_data_grouped_B[\"Gender\"] == \"Female\"]\n",
    "mos_data_grouped_B_males = mos_data_grouped_B[mos_data_grouped_B[\"Gender\"] == \"Male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(mos_data_grouped_B_females.index), len(mos_data_grouped_B_males.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_females = pd.merge(left=mos_data_grouped_B_females, right=weather_data_grouped, left_on='Trap Date', right_on='date_time_local')\n",
    "\n",
    "print(len(merged_data_females.index))\n",
    "\n",
    "merged_data_females.drop(columns=['date_time_local'], inplace=True) #redundent\n",
    "\n",
    "merged_data_females.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(merged_data_females['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_females['isWarm'] = np.where(merged_data_females['temperature'] >= 20, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_females['Genus'] = merged_data_females['Genus'].astype('category')\n",
    "merged_data_females['genusCat'] = merged_data_females['Genus'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_females[\"delta_pressure\"] = merged_data_females.apply(lambda x: x['pressure_station'] - x['pressure_sea'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(merged_data_females.corr(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['pressure_station', 'wind_speed', 'dew_point', 'temperature', 'genusCat', 'delta_pressure']\n",
    "X = merged_data_females[x_cols]\n",
    "y = merged_data_females['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_cols = ['pressure_station', 'wind_speed', 'dew_point', 'temperature', 'delta_pressure']\n",
    "\n",
    "\n",
    "X_stand = X.copy()\n",
    "X_norm = X.copy()\n",
    "X_both = X.copy()\n",
    "\n",
    "X_stand[x_cols] = StandardScaler().fit_transform(X[x_cols])\n",
    "X_norm[x_cols] = X[x_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "X_both[x_cols] = StandardScaler().fit_transform(X[x_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))[x_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "X_train_stand, X_test_stand, y_train_stand, y_test_stand = train_test_split(X_stand, y, test_size=test_size, random_state=42)\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, test_size=test_size, random_state=42)\n",
    "X_train_both, X_test_both, y_train_both, y_test_both = train_test_split(X_both, y, test_size=test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "\n",
    "lin_reg_norm = LinearRegression()\n",
    "lin_reg_norm.fit(X_train_norm,y_train_norm)\n",
    "\n",
    "lin_reg_stand = LinearRegression()\n",
    "lin_reg_stand.fit(X_train_stand,y_train_stand)\n",
    "\n",
    "lin_reg_both = LinearRegression()\n",
    "lin_reg_both.fit(X_train_both,y_train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_reg.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_reg_norm.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg_norm.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_reg_stand.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg_stand.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lin_reg_both.intercept_)\n",
    "coeff_df = pd.DataFrame(lin_reg_both.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = lin_reg.predict(X_test)\n",
    "pred_norm = lin_reg_norm.predict(X_test_norm)\n",
    "pred_stand = lin_reg_stand.predict(X_test_stand)\n",
    "pred_both = lin_reg_both.predict(X_test_both)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.scatter(y_test, pred, c='#2ca02c', marker='x', label='Original data')\n",
    "ax.scatter(y_test_norm, pred, c='r', marker='o', label='Normalized data')\n",
    "ax.scatter(y_test_stand, pred, c='b', marker='+', label='Standardized data')\n",
    "ax.scatter(y_test_both, pred, c='y', marker='s', label='Both data')\n",
    "\n",
    "plt.legend(loc='best');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot((y_test - pred), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lin_reg.predict(X_test)\n",
    "train_pred = lin_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_norm = lin_reg_norm.predict(X_test_norm)\n",
    "train_pred_norm = lin_reg_norm.predict(X_train_norm)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_norm, test_pred_norm)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_norm, train_pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_stand = lin_reg_stand.predict(X_test_stand)\n",
    "train_pred_stand = lin_reg_stand.predict(X_train_stand)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_stand, test_pred_stand)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_stand, train_pred_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred_both = lin_reg_both.predict(X_test_both)\n",
    "train_pred_both = lin_reg_both.predict(X_train_both)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_both, test_pred_both)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_both, train_pred_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())], [\"Linear Regression w/ norm\", *evaluate(y_test_norm, test_pred_norm) , cross_val(LinearRegression())], [\"Linear Regression w/ stand\", *evaluate(y_test_stand, test_pred_stand) , cross_val(LinearRegression())],[\"Linear Regression w/ both\", *evaluate(y_test_both, test_pred_both) , cross_val(LinearRegression())]], \n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_males = pd.merge(left=mos_data_grouped_B_males, right=weather_data_grouped, left_on='Trap Date', right_on='date_time_local')\n",
    "\n",
    "print(len(merged_data_males.index))\n",
    "\n",
    "merged_data_males.drop(columns=['date_time_local'], inplace=True) #redundent\n",
    "\n",
    "merged_data_males.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(merged_data_males['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_males['isWarm'] = np.where(merged_data_males['temperature'] >= 20, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_males['Genus'] = merged_data_males['Genus'].astype('category')\n",
    "merged_data_males['genusCat'] = merged_data_males['Genus'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_males[\"delta_pressure\"] = merged_data_males.apply(lambda x: x['pressure_station'] - x['pressure_sea'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(merged_data_males.corr(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [ 'wind_speed', 'temperature', 'health_index']\n",
    "X = merged_data_males[x_cols]\n",
    "y = merged_data_males['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(X_train, Y_train, X_test, Y_test, n_degree=11):\n",
    "    train_mse = []\n",
    "    test_mse = []\n",
    "    for degree in range(1,n_degree):\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "        sklreg = LinearRegression()\n",
    "        pipeline = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                             (\"linear_regression\", sklreg)])\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        Y_train_pred = pipeline.predict(X_train)\n",
    "        Y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "        train_mse.append(mean_squared_error(Y_train, Y_train_pred))\n",
    "        test_mse.append(mean_squared_error(Y_test, Y_test_pred))\n",
    "    return train_mse,test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_cols = ['wind_speed', 'temperature', 'health_index']\n",
    "\n",
    "\n",
    "X_stand = X.copy()\n",
    "X_norm = X.copy()\n",
    "X_both = X.copy()\n",
    "\n",
    "X_stand[x_cols] = StandardScaler().fit_transform(X[x_cols])\n",
    "X_norm[x_cols] = X[x_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "X_both[x_cols] = StandardScaler().fit_transform(X[x_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))[x_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "X_train_stand, X_test_stand, y_train_stand, y_test_stand = train_test_split(X_stand, y, test_size=test_size, random_state=42)\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, test_size=test_size, random_state=42)\n",
    "X_train_both, X_test_both, y_train_both, y_test_both = train_test_split(X_both, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse,test_mse = compute_mse(X_train,y_train,X_test,y_test)\n",
    "train_mse_stand,test_mse_stand, = compute_mse(X_train_stand,y_train_stand,X_test_stand,y_test_stand)\n",
    "train_mse_norm,test_mse_norm = compute_mse(X_train_norm,y_train_norm,X_test_norm,y_test_norm)\n",
    "train_mse_both,test_mse_both = compute_mse(X_train_both,y_train_both,X_test_both,y_test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(train_mse)+1),train_mse, label='train')\n",
    "plt.plot(range(1,len(test_mse)+1),test_mse, label='test')\n",
    "plt.title('MSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(train_mse_stand)+1),train_mse_stand, label='train')\n",
    "plt.plot(range(1,len(test_mse_stand)+1),test_mse_stand, label='test')\n",
    "plt.title('MSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(train_mse_norm)+1),train_mse_norm, label='train')\n",
    "plt.plot(range(1,len(test_mse_norm)+1),test_mse_norm, label='test')\n",
    "plt.title('MSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(train_mse_both)+1),train_mse_both, label='train')\n",
    "plt.plot(range(1,len(test_mse_both)+1),test_mse_both, label='test')\n",
    "plt.title('MSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best degree none: \",np.argmin(train_mse)+1)\n",
    "print(\"Best degree standarization: \",np.argmin(train_mse_stand)+1)\n",
    "print(\"Best degree normalization: \",np.argmin(train_mse_norm)+1)\n",
    "print(\"Best degree both: \",np.argmin(train_mse_both)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=np.argmin(train_mse)+1, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "poly_features_stand = PolynomialFeatures(degree=np.argmin(train_mse_stand )+1, include_bias=False)\n",
    "X_poly_stand = poly_features_stand.fit_transform(X_stand)\n",
    "\n",
    "poly_features_norm = PolynomialFeatures(degree=np.argmin(train_mse_norm)+1, include_bias=False)\n",
    "X_poly_norm = poly_features_norm.fit_transform(X_norm)\n",
    "\n",
    "poly_features_both = PolynomialFeatures(degree=np.argmin(train_mse_both)+1, include_bias=False)\n",
    "X_poly_both = poly_features_both.fit_transform(X_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_best = SelectKBest(f_regression,5).fit_transform(X_poly, y)\n",
    "X_best_stand = SelectKBest(f_regression,5).fit_transform(X_poly_stand, y)\n",
    "X_best_norm = SelectKBest(f_regression,5).fit_transform(X_poly_norm, y)\n",
    "X_best_both = SelectKBest(f_regression,5).fit_transform(X_poly_both, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_best,y)\n",
    "\n",
    "lin_reg_norm = LinearRegression()\n",
    "lin_reg_norm.fit(X_best_norm,y)\n",
    "\n",
    "lin_reg_stand = LinearRegression()\n",
    "lin_reg_stand.fit(X_best_stand,y)\n",
    "\n",
    "lin_reg_both = LinearRegression()\n",
    "lin_reg_both.fit(X_best_both,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn as sk\n",
    "# stand_scaler= sk.preprocessing.StandardScaler()\n",
    "#X_train_norm, X_test_norm, y_train_norm, y_test_norm\n",
    "poly_features = PolynomialFeatures(degree=np.argmin(train_mse)+1,include_bias=False)\n",
    "selectbest=SelectKBest(f_regression,5)\n",
    "polpipeline = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                        (\"SelectKBest\",selectbest),\n",
    "                     (\"linear_regression\", LinearRegression())])\n",
    "polpipeline.fit(X_train_norm,y_train_norm)\n",
    "pred_pip_train=polpipeline.predict(X_train_norm)\n",
    "pred_pip_test=polpipeline.predict(X_test_norm)\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test_norm, pred_pip_test)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train_norm, pred_pip_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = lin_reg.predict(X_best)\n",
    "pred_norm = lin_reg_norm.predict(X_best_norm)\n",
    "pred_stand = lin_reg_stand.predict(X_best_stand)\n",
    "pred_both = lin_reg_both.predict(X_best_both)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.scatter(y, pred, c='#2ca02c', marker='x', label='Original data')\n",
    "ax.scatter(y, pred, c='r', marker='o', label='Normalized data')\n",
    "ax.scatter(y, pred, c='b', marker='+', label='Standardized data')\n",
    "ax.scatter(y, pred, c='y', marker='s', label='Both data')\n",
    "\n",
    "plt.legend(loc='best');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot((y - pred), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y, pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y, pred_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y, pred_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=[[\"Polynomial Regression\", *evaluate(y, pred) , cross_val(LinearRegression())], [\"Polynomial Regression w/ norm\", *evaluate(y_test_norm, test_pred_norm) , cross_val(LinearRegression())], [\"Polynomial Regression w/ stand\", *evaluate(y_test_stand, test_pred_stand) , cross_val(LinearRegression())],[\"Linear Regression w/ both\", *evaluate(y_test_both, test_pred_both) , cross_val(LinearRegression())]], \n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
