{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "- 3 regression models\n",
    "\n",
    "### 1) Linear Regression\n",
    "- no_of_Mosquito = function(weather_features^A)\n",
    "\n",
    "### 2) Linear Regression\n",
    "- no_of_Mosquito_female = function(weather_features^B)\n",
    "- OR no_of_Mosquito_male = function(weather_features^C)\n",
    "- Preferably do both\n",
    "\n",
    "### 3) Polynomial Regression\n",
    "- no_of_Mosquito_female = function(weather_features^B)\n",
    "- OR no_of_Mosquito_male = function(weather_features^C)\n",
    "- Preferably do both\n",
    "\n",
    "NOTE: A, B, C are a note that a subset of the inputs is used.\n",
    "Use different cost functions, perform analysis of constructed models, apply normalization and standardization, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "- You need to combine both data sets to prepare a data set suitable for model construction.\n",
    "- Both data sets have different ‘time grid’ so you need to resolve it.\n",
    "- You have to aggregate data points over time, and different mosquito species.\n",
    "\n",
    "### Mosquito data notes:\n",
    "From website: Capture results of mosquitoes from various locations in Edmonton. These collections are from standard New Jersey light traps that are commonly used to record changes in abundance of mosquitoes before and after control campaigns and to compare seasonal and annual fluctuations in population. Since not all mosquito species are attracted equally to light traps, the City uses a variety of other trapping and survey methods (with their own limitations) to monitor mosquitoes. Not all trap collection sites are factored into the historical averages. Some data can be incomplete due to trap failure. Some trap locations change over time. Trap collections reflect, not absolute population levels, but mosquito activity, which is influenced by changing environmental conditions (temperature, humidity, wind, etc.). The weekly averages do not include any male mosquitoes or any females of species that do not typically bite people. Each data set reflects the mosquito activity of the week previous to the collection date.\n",
    "\n",
    "To complement this dataset, there is the Rainfall Gauge data which measures rainfall data in the Greater Edmonton area.\n",
    "\n",
    "\n",
    "- Data collected from May 1990 onward\n",
    "- Data is updated weekly and collected automatically\n",
    "\n",
    "#### Columns:\n",
    "\n",
    "- Trap Date (Date & Time Floating timestamp): date when the mosquito traps are collected. An empty mosquito traps are replaced for the next collection at the same time.\n",
    "- Genus (Text): When biologists talk about a genus, they mean one or more species of animals or plants that are closely related to each other. Low-level taxonomic ranking for biological classification.\n",
    "- Specific Epithet (Text): lowest taxonomic rank and having common characteristics and (usually) capable of mating with one another.\n",
    "- Gender (Text): male or female\n",
    "- IDd (Text or NaN): specimens too damaged for precise identification or not sigificant in the mosquito program are marked with a value of UnID.\n",
    "- Count (Number/Int): number of mosquitoes trapped at this Trap Region on this Trap Date.\n",
    "- Trap Region (Text): The description of where the mosquito trap was placed.\n",
    "- Include (Text or NaN): blank or no.\n",
    "- Comparison Group (Text): Trap areas used to evaluate mosquito program efficacy.\n",
    "- Latitude (Number/Float): geographic coordinate that specifies north-south position of mosquito trap.\n",
    "- Longitude (Number/Float): The geographic coordinate that specifies the east–west position of the mosquito trap.\n",
    "- Location (Point): The combination of latitude/longitude for mapping purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edmoton weather notes:\n",
    "- Source: weatherstats.ca based on Environment and Climate Change Canada data\n",
    "\n",
    "### Columns (personal notes):\n",
    "- date_time_local (Date/Time human format YYYY-MM-DD HH:MM:SS TZ): date and time data recorded.\n",
    "- unixtime: unix time format\n",
    "- pressure_station (float or NaN):\n",
    "- pressure_sea (float or NaN):\n",
    "- wind_dir (Text or NaN): wind direction in compass directions (SW, WSW ... etc)\n",
    "- wind_dir_10s (float or NaN): \n",
    "- wind_speed (float or NaN): speed of the wind in CONVUNIT <- TBD\n",
    "- wind_gust (NaN or float): \n",
    "- relative_humidty (float or NaN):\n",
    "- dew_point (float or NaN): \n",
    "- temperature (float or NaN): temp recorded\n",
    "- windchill (float or NaN):\n",
    "- humidex (float or NaN):\n",
    "- visibility (float or NaN):\n",
    "- health_index (float or NaN):\n",
    "- cloud_cover_4 (float or NaN):\n",
    "- cloud_cover_8 (float or NaN):\n",
    "- cloud_cover_10 (float or NaN):\n",
    "- solar_radiation (float or NaN):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white bg for sns plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data = pd.read_csv(\"./data/mosquito_data.csv\")\n",
    "weather_data = pd.read_csv(\"./data/weather_data.csv\")\n",
    "\n",
    "\n",
    "orig_mos_data = mos_data.copy()\n",
    "orig_weather_data = weather_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat=mos_data[mos_data[\"new_trap_date\" ]==\"2017-06-13\"]\n",
    "#mos_data[\"new_trap_date\"].value_counts()\n",
    "#mosdat=mos_data.sort_values(by=\"new_trap_date\",inplace=False,ascending=False)\n",
    "#mergedata=pd.merge(mosdat,weather_data,how='right', on=['new_trap_date', 'new_date_time_local'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mos_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop visibility, cloud_cover_4, cloud_cover_8, cloud_cover_10, solar_radiation as they are all NaN, also humidex and windchill and windgust as they are mostly NaN and nothing that we can do about\n",
    "weather_data=orig_weather_data.drop(columns=[\"visibility\", \"cloud_cover_4\", \"cloud_cover_8\", \"cloud_cover_10\", \"solar_radiation\", \"wind_gust\", \"windchill\", \"humidex\"], inplace=False)\n",
    "# and drop the row with missing values\n",
    "#weather_data.dropna(inplace=True)\n",
    "print(weather_data.isnull().sum())\n",
    "#drop idd include\n",
    "mos_data=orig_mos_data.drop(columns=[\"idd\",\"include\",\"geocoded_column\",\"latitude\",\"longitude\",\"geocoded_column\"])\n",
    "#print(mos_data.isnull().sum())\n",
    "#mos_data.count()\n",
    "#weather_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data[\"trap_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date and time \n",
    "We can see that both datasets are timestamped but the mosquito dataset is timestamped.\n",
    "Our first task would be combining both datasets by day and month and year ignoring HH:MM:DD.\n",
    "- Create a new_trap_date column in mos_data following the format YYYY-MM-DD\n",
    "- Drop trap_date from mos_data\n",
    "- create new_date column in weather_data following the format YYYY-MM-DD\n",
    "- Drop date_time_local and unixtime in weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mos_data[\"new_trap_date\"] = mos_data.apply(lambda x: x[\"trap_date\"].split(\"T\")[0], axis=1)\n",
    "#mos_data.drop(columns=[\"trap_date\"], inplace=True) #redundant\n",
    "\n",
    "mos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#convert new_trap_date into datetime\n",
    "format = '%Y-%m-%d'\n",
    "mos_data[\"new_trap_date\"] = pd.to_datetime(mos_data[\"new_trap_date\"], format=format)\n",
    "\n",
    "mos_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mountain Daylight Time (MDT) to Mountain Standard Time (MST)\n",
    "def Tzone(x):\n",
    "    timelist=x[\"date_time_local\"].split(\" \")\n",
    "    YD=timelist[0]+timelist[1]\n",
    "    timec=time.mktime(time.strptime(YD,'%Y-%m-%d%H:%M:%S'))\n",
    "    if timelist[2]=='MDT':\n",
    "        timec=timec+3600 # add one hour \n",
    "    return time.strftime(\"%Y-%m-%d\", time.localtime(timec))\n",
    "weather_data[\"new_date_time_local\"] = weather_data.apply(lambda x: Tzone(x), axis=1)\n",
    "weather_data.drop(columns=[\"date_time_local\", \"unixtime\"], inplace=True)\n",
    "\n",
    "weather_data[\"new_date_time_local\"] = pd.to_datetime(weather_data[\"new_date_time_local\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges of date/time columns in both dataset\n",
    "mos_date_range = str(mos_data['new_trap_date'].dt.date.min()) + ' to ' +str(mos_data['new_trap_date'].dt.date.max())\n",
    "weather_date_range = str(weather_data['new_date_time_local'].dt.date.min()) + ' to ' +str(weather_data['new_date_time_local'].dt.date.max())\n",
    "\n",
    "print(\"Range of dates in mosquito dataset is {}\".format(mos_date_range))\n",
    "print(\"Range of dates in weather dataset is {}\".format(weather_date_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the mosquito dataset is covering a much bigger range so everything before 2016-12-18 and after 2018-12-18 will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_remove = weather_data['new_date_time_local'].min()\n",
    "end_remove = weather_data['new_date_time_local'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mos_data = mos_data.loc[(mos_data[\"new_trap_date\"] >= start_remove) & (mos_data[\"new_trap_date\"] <= end_remove) ]\n",
    "\n",
    "mos_date_range = str(mos_data['new_trap_date'].dt.date.min())+' to ' + str(mos_data['new_trap_date'].dt.date.max())\n",
    "print(\"Range of dates in mosquito dataset is {}\".format(mos_date_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.sort_values(by=\"new_trap_date\",inplace=True,ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current distribution:\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = mos_data[\"count\"].hist(bins=500, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "mos_data[\"count\"].plot(kind='density', color='teal')\n",
    "\n",
    "\n",
    "ax.set(xlabel=\"count\")\n",
    "plt.xlim(-10,400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mos_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mos_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping weather data on date column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(weather_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace null data in weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like health index is normally distributed so its safe to replace na with mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perday_weather_data = weather_data.groupby(\"new_date_time_local\").agg({ #,as_index=False\n",
    "    #\"new_date_time_local\": 'first',\n",
    "    \"pressure_station\": lambda x: round(x.mean(),2),\n",
    "    \"pressure_sea\": lambda x: round(x.mean(),1),\n",
    "    \"wind_dir\":lambda x: x.value_counts().index[0],\n",
    "    \"wind_dir_10s\":lambda x: x.value_counts().index[0],\n",
    "    \"wind_speed\":lambda x: round(x.mean(),1),#x.mode().iloc[0],\n",
    "    \"relative_humidity\":lambda x: x.median(),\n",
    "    \"dew_point\":lambda x: x.median(),\n",
    "    \"temperature\":lambda x: x.median(),\n",
    "    \"health_index\": lambda x: round(x.mean(),1),\n",
    "})\n",
    "#perday_weather_data.reset_index()\n",
    "perday_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seperate the wind_dir into 4 columns : wind_dir_W,wind_dir_S,wind_dir_N,wind_dir_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dirc=perday_weather_data[\"wind_dir\"].str.split('', expand=True)\n",
    "wind_dirc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_num=wind_dirc.apply(lambda x:x.value_counts()[1:4],axis = 1).fillna(0)\n",
    "wind_dir_num.rename(columns={'E':'wind_dir_E', 'N': 'wind_dir_N', 'S': 'wind_dir_S', 'W': 'wind_dir_W'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perday_weather_data=perday_weather_data.join(wind_dir_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perday_weather_data=perday_weather_data.drop(columns=[\"wind_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the delta_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perday_weather_data[\"delta_pressure\"]=perday_weather_data.apply(lambda x:x[\"pressure_station\"]-x[\"pressure_sea\"], axis=1)\n",
    "perday_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_mos_data=mos_data.drop(columns=[\"trap_date\"])\n",
    "#index_mos_data=mos_data.set_index(\"new_trap_date\")\n",
    "\n",
    "index_mos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perday_weather_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perday_weather_data = perday_weather_data.set_index（'cuspin'，append = True）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedata=pd.merge(left=perday_weather_data , right=mos_data, left_on=\"new_date_time_local\", right_on=\"new_trap_date\", how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedata.isnull().sum()\n",
    "mergedata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a lot of data of mos_data is null, we need to fill them and because the number of mosquitos would not change sharply, so we can assume the data of mosquitos is same for 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_mos=index_mos_data.groupby(\"new_trap_date\")\n",
    "group_mo=index_mos_data[index_mos_data[\"new_trap_date\"]==\"2017-05-23\"]\n",
    "\n",
    "end_date=group_mo[\"new_trap_date\"].dt.date.min()+timedelta(days=2)\n",
    "\n",
    "date_rang=pd.DataFrame({\"date\":pd.date_range(end=pd.to_datetime(end_date),periods=5)})\n",
    "date_rang=date_rang.groupby(\"date\").apply(lambda df,group=group_mo:group)\n",
    "date_rang=date_rang.reset_index().drop(columns=[\"level_1\"])\n",
    "date_rang\n",
    "#pd.Timestamp(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mos_data(x):\n",
    "    end_date=x[\"new_trap_date\"].dt.date.min()+timedelta(days=2)\n",
    "    date_rang=pd.date_range(end=end_date,periods=5)\n",
    "    date_rang=pd.DataFrame({\"date\":pd.date_range(end=pd.to_datetime(end_date),periods=5)})\n",
    "    date_rang=date_rang.groupby(\"date\").apply(lambda df,group_mo=x:group_mo)\n",
    "    return date_rang.reset_index().drop(columns=[\"level_1\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullday_mos=index_mos_data.groupby(\"new_trap_date\", as_index=False).apply(fill_mos_data)\n",
    "#fullday_mos=fullday_mos[fullday_mos[\"trap_region\"]==\"Rural-West\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedata=pd.merge(left=perday_weather_data , right=fullday_mos, left_on=\"new_date_time_local\", right_on=\"date\", how='right').set_index(\"date\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine nearly all data from weather and mosquito datasets, and there aren't empty values occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Linear regression num of Mosquitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features for Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(mergedata)\n",
    "Lr_data=mergedata.drop(columns=[\"pressure_sea\",\"genus\",\"specific_epithet\",\"gender\",\"trap_region\",\"comparison_group\"])\n",
    "#Lr_data=Lr_data.loc[Lr_data[\"count\"]<=400]\n",
    "Lr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lr_data=Lr_data.groupby(\"new_trap_date\").agg({\n",
    "#     'pressure_station':'mean',\n",
    "#     'delta_pressure':'mean',\n",
    "#     'wind_dir_10s':'mean',\n",
    "#     'wind_speed':'mean',\n",
    "#     'relative_humidity':'mean',\n",
    "#     'dew_point':'mean',\n",
    "#     'temperature':'mean',\n",
    "#     'health_index':'mean',\n",
    "#     'wind_dir_W':'mean',\n",
    "#     'count':'median',\n",
    "#     #'new_trap_date':'first'\n",
    "# }).reset_index()\n",
    "#Lr_data=Lr_data[Lr_data[\"count\"]<=Lr_data[\"count\"].describe()[\"75%\"] ]\n",
    "Lr_data=Lr_data.groupby(\"date\").agg(\"median\").reset_index()\n",
    "#Lr_data[\"count\"]=Lr_data.groupby(\"new_trap_date\")[\"count\"].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(Lr_data.corr(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pressure_station\twind_dir_10s\twind_speed\trelative_humidity\tdew_point\ttemperature\thealth_index\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Lr_data[\"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_data=Lr_data.loc[:,['count']].values\n",
    "#\"delta_pressure\",\"relative_humidity\",\"dew_point\"\n",
    "Feature_data=Lr_data.loc[:,[\"pressure_station\",\"wind_dir_10s\",\"wind_speed\",\"relative_humidity\",\"dew_point\",\"temperature\",\"health_index\"]].values\n",
    "\n",
    "Feature_data_stand= sk.preprocessing.scale(Feature_data)\n",
    "Feature_data_norm= sk.preprocessing.minmax_scale(Feature_data)\n",
    "Feature_data_normalize=sk.preprocessing.normalize(Feature_data)\n",
    "\n",
    "stand_scaler= sk.preprocessing.StandardScaler()\n",
    "norm_scaler=sk.preprocessing.MinMaxScaler()\n",
    "normalize_scaler=sk.preprocessing.Normalizer()\n",
    "sklreg = linear_model.LinearRegression()\n",
    "normfeature=norm_scaler.fit_transform(Feature_data)\n",
    "#Feature_data=Lr_data.drop(columns=[\"date\",\"count\"]).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( Feature_data , Target_data , test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X,Y,model,scoring_type):\n",
    "    results=[]\n",
    "    for score in scoring_type:\n",
    "        scores = cross_val_score(model, X, Y,\n",
    "                                     scoring=score, \n",
    "                                     cv=10, error_score=np.nan)\n",
    "        #print(score,\":\", \"mean:\", scores.mean(),\"std:\", scores.std())\n",
    "        results.append(scores.mean())\n",
    "    series=pd.Series(results,index=scoring_type)\n",
    "    return series\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear=sklreg\n",
    "Linear_stand = Pipeline([(\"scaler\",stand_scaler),\n",
    "                     (\"linear_regression\", sklreg)])\n",
    "Linear_norm = Pipeline([(\"scaler\",norm_scaler),\n",
    "                     (\"linear_regression\", sklreg)])\n",
    "Linear_normalize = Pipeline([(\"scaler\",normalize_scaler),\n",
    "                     (\"linear_regression\", sklreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "soclling=[\"neg_mean_absolute_error\",\"neg_mean_squared_error\",\"neg_root_mean_squared_error\",\"r2\"]\n",
    "series=cross_val(Feature_data,Target_data,Linear,soclling)\n",
    "series.name=\"Liner\"\n",
    "results_df=results_df.append(series)\n",
    "########\n",
    "series=cross_val(Feature_data,Target_data,Linear_stand,soclling)\n",
    "series.name=\"Linear_stand\"\n",
    "results_df=results_df.append(series)\n",
    "########\n",
    "series=cross_val(Feature_data,Target_data,Linear_norm,soclling)\n",
    "series.name=\"Linear_norm\"\n",
    "results_df=results_df.append(series)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sklreg = linear_model.LinearRegression()\n",
    "sklreg.fit(X_train,Y_train)\n",
    "np.array([sklreg.intercept_,sklreg.coef_[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_sk = sklreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:,2],Y_test,label='real')\n",
    "plt.scatter(X_test[:,2],Y_pred_sk, label='pred')\n",
    "#plt.scatter(Y_test,Y_pred_sk, label='comparison')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:,0],Y_test,label='real')\n",
    "plt.scatter(X_test[:,0],Y_pred_sk, label='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model,x,y):\n",
    "    pred = cross_val_score(model, x, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = sklreg.predict(X_test)\n",
    "train_pred = sklreg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(Y_test, test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(Y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(Y_test, test_pred) , cross_val(sklreg,Feature_data,Target_data)]], \n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polynomial models for predicting the number of female or male mosquitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Po_data=mergedata.drop(columns=[\"pressure_sea\",\"genus\",\"specific_epithet\",\"trap_region\",\"comparison_group\",\"new_trap_date\"])\n",
    "Po_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_female_male(x):\n",
    "    x[\"Female\"]= 0 if x[x[\"gender\"]==\"Female\"][\"count\"].sum()==0 else x[x[\"gender\"]==\"Female\"][\"count\"].median()\n",
    "    x[\"Male\"]= 0 if x[x[\"gender\"]==\"Male\"][\"count\"].sum()==0 else x[x[\"gender\"]==\"Male\"][\"count\"].median()\n",
    "    return x[0:1].drop(columns=[\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Po_data=Po_data[Po_data[\"count\"]<=(Po_data[\"count\"].describe()[\"75%\"]+Po_data[\"count\"].describe()[\"std\"])]\n",
    "Po_data=Po_data.groupby(\"date\", as_index=False).apply(count_female_male).droplevel(0)\n",
    "Po_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(Po_data.corr(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build polynomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_data=Po_data.loc[:,['Female']].values\n",
    "Feature_data=Po_data.loc[:,[\"dew_point\"]] .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split( Feature_data , Target_data , test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_cv(X, Y, n_degree=11):\n",
    "    mse = []\n",
    "    std = []\n",
    "    for degree in range(1,n_degree):\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "        sklreg = linear_model.LinearRegression()\n",
    "        pipeline = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                             (\"linear_regression\", sklreg)])\n",
    "        pipeline.fit(X, Y)\n",
    "\n",
    "        # Evaluate the models using crossvalidation\n",
    "        scores = cross_val_score(pipeline, X, Y,\n",
    "                                 scoring=\"neg_mean_squared_error\", \n",
    "                                 cv=10, error_score=np.nan)\n",
    "        \n",
    "        mse.append(-scores.mean())\n",
    "        std.append(scores.std())       \n",
    "    return mse,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(X_train, Y_train, X_test, Y_test, n_degree=11):\n",
    "    train_mse = []\n",
    "    test_mse = []\n",
    "    for degree in range(1,n_degree):\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "        sklreg = linear_model.LinearRegression()\n",
    "        pipeline = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                             (\"linear_regression\", sklreg)])\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        Y_train_pred = pipeline.predict(X_train)\n",
    "        Y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "        train_mse.append(mean_squared_error(Y_train, Y_train_pred))\n",
    "        test_mse.append(mean_squared_error(Y_test, Y_test_pred))\n",
    "    return train_mse,test_mse\n",
    "\n",
    "def compute_scale_cov(X_train, Y_train, X_test, Y_test,scale_model, n_degree=11):\n",
    "    train_mse = []\n",
    "    test_mse = []\n",
    "    for degree in range(1,n_degree):\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "        sklreg = linear_model.LinearRegression()\n",
    "        pipeline = Pipeline([(\"scaler\",scale_model),\n",
    "                             (\"polynomial_features\", poly_features),\n",
    "                             (\"linear_regression\", sklreg)])\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        Y_train_pred = pipeline.predict(X_train)\n",
    "        Y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "        train_mse.append(mean_squared_error(Y_train, Y_train_pred))\n",
    "        test_mse.append(mean_squared_error(Y_test, Y_test_pred))\n",
    "    return train_mse,test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse,std = compute_mse_cv(X_train,Y_train,10)\n",
    "plt.plot(range(1,len(mse)+1),mse, label='MSE')\n",
    "plt.plot(range(1,len(std)+1),std, label='std')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse,test_mse = compute_mse(X_train,Y_train,X_test,Y_test,15)\n",
    "plt.plot(range(1,len(train_mse)+1),train_mse, label='train')\n",
    "plt.plot(range(1,len(test_mse)+1),test_mse, label='test')\n",
    "plt.title('MSE')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances in normalization and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scaler= sk.preprocessing.StandardScaler()\n",
    "norm_scaler=sk.preprocessing.MinMaxScaler()\n",
    "normalize_scaler=sk.preprocessing.Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse,test_mse = compute_scale_cov(X_train,Y_train,X_test,Y_test,norm_scaler,15)\n",
    "plt.plot(range(1,len(train_mse)+1),train_mse, label='train')\n",
    "plt.plot(range(1,len(test_mse)+1),test_mse, label='test')\n",
    "plt.title('MSE')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose 13 degree as the best degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=4)\n",
    "sklreg = linear_model.LinearRegression()\n",
    "polpipeline = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                     (\"linear_regression\", sklreg)])\n",
    "polpipeline.fit(X_train,Y_train)\n",
    "Predict_Y=polpipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "soclling=[\"neg_mean_absolute_error\",\"neg_mean_squared_error\",\"neg_root_mean_squared_error\",\"r2\"]\n",
    "series=cross_val(X_train,Y_train,polpipeline,soclling)\n",
    "series.name=\"Polynomial model\"\n",
    "results_df=results_df.append(series)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred=evaluate(Y_test,Predict_Y)\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(Y_test, Predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
